# 哈希算法在分布式系统中的应用
### 一、负载均衡
我们知道，负载均衡算法有很多，比如轮询、随机、加权轮询等。那如何才能实现一个会话粘滞(session sticky)的负载均衡算法呢？也就是说，我们需要在同一个客户端
，在一次会话中的所有请求都路由到同一个服务器上。

最直接的方法就是，维护一张映射表，这张表的内容是客户端IP地址或者会话ID与服务器编号的映射关系。客户端发出的每次请求，都要先在映射表中查找应该路由到的服务器
编号，然后再请求编号对应的服务器。这种方法简单直观，但也有几个弊端：
* 如果客户端很多，映射表可能会很大，比较浪费内存空间；
* 客户端下线、上线，服务器扩容、缩容都会导致映射失败，这样维护映射表的成本就很大；

如果借助哈希算法，这些问题都可以非常完美地解决。可以通过哈希算法，对客户端IP地址或者会话ID计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。这样我们就
可以把同一个IP过来的所有请求，都路由到同一个后端服务器上。

### 二、数据分片
哈希算法还可以用于数据的分片。举两个例子：
###### 1、如何统计"搜索关键词"出现的次数？
假如我们有 1T 的日志文件，这里面记录了用户的搜索关键词，我们想要快速统计出每个关键词被搜索的次数，该怎么做呢？

我们来分析一下。这个问题有两个难点，第一个是搜索日志很大，没办法放到一台机器的内存中。第二个难点是，如果只用一台机器来处理这么巨大的数据，处理时间会很长。

针对这两个难点，我们可以先对数据进行分片，然后采用多台机器处理的方法，来提高处理速度。具体的思路是这样的：为了提高处理速度，我们用n台机器并行处理。我们从搜索
记录的日志文件中，依次读出每个搜索关键词，并且通过哈希函数计算哈希值，然后再跟n取模，最终得到的值，就是应该被分配到的机器编号。

这样，哈希值相同的搜索关键词就别分配到了同一个机器上。也就是说，同一个关键词会被分配到同一机器上。每个机器会分别计算关键词出现的次数，最后合并起来就是
最终的结果。

实际上，这里的处理过程也是MapReduce的基本设计思想。

###### 2、如何快速判断图片是否在图库中？
如何快速判断图片是否在图库中？给每个图片取唯一标识（或者信息摘要），然后构建散列表。

假设现在我们的图库中有1亿张图片，很显然，在单台机器上构建散列表是行不通的。因为单机器的内存有限，1亿张图片构建散列表显然远远超出了单机机器的内存上线。

我们同样可以对数据进行分片，然后采用多机处理。我们准备n台机器，让每台机器只维护某一部分图片对应的散列表。我们每次从图库中读取一些图片，计算唯一标识，然后与机器个数n求余取模，得到的值就是机器对应要分配的机器编号，然后将这个图片的唯一标识和图片路径发往对应的机器构建散列表。

当我们要判断一个图片是否在图库中的时候，我们通过同样的哈希算法，计算这个图片的唯一标识，然后与机器个数n求余取模。假设得到的值是k，那就是去k的机器构建
的散列表中查找。

现在，我们来估算一下，给这1亿张图片构建散列表大约需要多少台机器。

散列表中每个数据单元包含两个信息，哈希值和图片文件的路径。假设我们通过MD5来计算哈希值，那长度就是128比特，也就是16字节。文件路径长度的上限是256字节，我们可以假设平均长度是128字节。如果我们用链表法来解决冲突，那还需要存储指针，指针只占用8个字节。所以，散列表中每个数据单元就占用152字节（这里只是估算，并不准确）。

假设一台机器的内存大小为2GB，散列表的装载因子为0.75，那一台机器可以给大约1000万（2GB*0.75/152）张图片构建散列表。
